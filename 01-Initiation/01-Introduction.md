# Kubernetes ‚Äî Fiche 1 : Introduction √† Kubernetes

**Prise en main, d√©ploiement et migration depuis Docker Compose**

## Objectifs

- D√©marrer un cluster Kubernetes local avec Docker Desktop
- Comprendre les concepts fondamentaux : Pod, Deployment, Service
- √âcrire et appliquer des manifestes YAML d√©claratifs
- G√©rer le cycle de vie des pods (scaling, rolling update, self-healing)
- Porter une architecture Docker Compose vers Kubernetes

> üìù **Pr√©requis**
>
> Docker Desktop install√© avec Kubernetes activ√©, bonnes bases Docker (images, Dockerfile, Docker Compose).

---

## 1. Prise en main de Kubernetes

### a. D√©marrer le cluster

Docker Desktop embarque un cluster Kubernetes qu'il suffit d'activer. Contrairement √† un cluster de production qui s'√©tend sur plusieurs machines, ce cluster tourne enti√®rement en local ‚Äî c'est parfait pour apprendre.

#### üìã D√©marrage du cluster K8s

1. Ouvrez Docker Desktop, allez dans **Settings**, cochez **Enable Kubernetes** puis cliquez sur **Apply** puis **Install**.
2. Une fois le cluster lanc√©, son statut appara√Æt dans le bandeau bas de Docker Desktop.
3. Ouvrez un terminal et ex√©cutez les commandes suivantes pour v√©rifier l'installation :

```bash
kubectl version
kubectl cluster-info
kubectl get nodes
```

> üí° **kubectl** est l'√©quivalent de la commande `docker`, mais pour piloter un cluster Kubernetes. Kubernetes (abr√©g√© k8s) orchestre des conteneurs sur plusieurs machines, en g√©rant le scaling, la r√©partition de charge et l'auto-r√©paration.

---

### b. Pr√©parer les images Docker

Avant de d√©ployer quoi que ce soit sur K8s, il faut des images Docker. Nous allons en construire 3 versions successives d'une API Python.

#### üìã Construction de 3 versions d'une image

1. Cr√©ez un fichier `app.py` contenant une API FastAPI avec deux routes : une route `/` et une route `/version`.

```python
from fastapi import FastAPI

app = FastAPI()

@app.get("/")
async def root():
    return {"message": "Hello World"}

@app.get("/version")
async def version():
    return {"version": "0.1.0"}
```

2. Cr√©ez le `Dockerfile` suivant √† la racine du dossier 01 :

```dockerfile
FROM python:3.11-slim

WORKDIR /app

RUN pip install fastapi uvicorn

COPY app.py .

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

3. Construisez et testez la premi√®re image :

```bash
docker build -t api:0.1.0 .
docker run --rm -p 8000:8000 api:0.1.0
```

Ouvrez **http://localhost:8000/version** ‚Äî vous devriez voir `{"version": "0.1.0"}`.

4. Modifiez `app.py` (changez le num√©ro de version et ajoutez une route) puis produisez les deux versions suivantes :

```bash
# Apr√®s modification pour la version 0.2.0
docker build -t api:0.2.0 .

# Apr√®s modification pour la version 0.3.0
docker build -t api:0.3.0 .
```

√Ä la fin de cette √©tape, vous disposez de 3 images locales : `api:0.1.0`, `api:0.2.0` et `api:0.3.0`. (v√©rifiez avec `docker images`)

### c. D√©ployer un Pod

Le Pod est l'unit√© de base de Kubernetes : il encapsule un ou plusieurs conteneurs qui partagent le m√™me r√©seau et le m√™me stockage local. C'est l'√©quivalent K8s d'un conteneur Docker, en un peu plus riche.

Un Pod est toujours d√©crit dans un fichier YAML que l'on soumet √† Kubernetes. K8s se charge ensuite de faire converger l'√©tat r√©el vers l'√©tat d√©clar√©.

#### üìã D√©ploiement d'un premier Pod

1. Cr√©ez un dossier `k8s/`, puis un fichier `pod.yaml` √† l'int√©rieur.

2. Renseignez-y le manifeste suivant :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: api-pod
  labels:
    app: api
    version: 0.1.0
spec:
  containers:
  - name: api
    image: api:0.1.0
    ports:
    - containerPort: 8000
```

3. Soumettez ce fichier au cluster avec `kubectl apply -f k8s/pod.yaml`, puis listez les pods actifs.

4. Inspectez le pod en d√©tail avec `kubectl get pod api-pod -o yaml`. Rep√©rez les champs `spec` (√©tat d√©sir√©) et `status` (√©tat r√©el).

5. Ouvrir un shell dans le pod et tester l'API en interne

Ouvrez un shell interactif dans le pod :

```bash
kubectl exec -it api-pod -- /bin/bash
```

Une fois dans le shell, testez que l'API r√©pond bien en interne :

```bash
python -c "import urllib.request; print(urllib.request.urlopen('http://localhost:8000').read())"
python -c "import urllib.request; print(urllib.request.urlopen('http://localhost:8000/version').read())"
```

> üí° L'image `python:3.11-slim` est volontairement minimaliste et ne contient pas `curl`. On utilise directement le module `urllib` de Python, toujours disponible dans une image Python.

Quittez le shell avec `exit`.

6. Afficher les logs et acc√©der √† l'API depuis le navigateur

Affichez les logs du pod :

```bash
kubectl logs api-pod
```

Exposez le pod en local avec un port-forward :

```bash
kubectl port-forward pod/api-pod 8000:8000
```

Ouvrez **http://localhost:8000/docs** dans votre navigateur. Vous verrez l'interface Swagger de FastAPI.

Une fois la v√©rification faite, arr√™tez le port-forward avec `Ctrl+C` dans le terminal.

> üí° Le port-forward cr√©e un tunnel temporaire entre votre poste et le pod. C'est utile pour d√©boguer, mais ce n'est pas la fa√ßon d'exposer un service en production ‚Äî c'est le r√¥le du Service, que nous verrons √† la section suivante.

7. Supprimer le pod

Deux fa√ßons de supprimer le pod, au choix :

```bash
# Par son nom
kubectl delete pod api-pod

# Ou via le fichier YAML (supprime toutes les ressources d√©clar√©es dans le fichier)
kubectl delete -f k8s/pod.yaml
```

V√©rifiez qu'il a bien disparu :

```bash
kubectl get pods
```

Vous remarquerez qu'il ne r√©appara√Æt **pas** tout seul ‚Äî un Pod seul n'a pas de m√©canisme de self-healing. C'est exactement le probl√®me que r√®gle le **Deployment** √† la section suivante.

> üí° En pratique, `kubectl delete -f fichier.yaml` est la m√©thode recommand√©e car elle supprime toutes les ressources d√©clar√©es dans le fichier en une seule commande, sans avoir √† retenir les noms.

#### üìã Plusieurs pods en parall√®le

1. √âditez `pod.yaml` pour d√©clarer 3 pods (un par version d'image) dans le m√™me fichier, s√©par√©s par `---` :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: api-pod-1
  labels:
    app: api
    version: 0.1.0
spec:
  containers:
  - name: api
    image: api:0.1.0
    ports:
    - containerPort: 8000
---
apiVersion: v1
kind: Pod
metadata:
  name: api-pod-2
  labels:
    app: api
    version: 0.2.0
spec:
  containers:
  - name: api
    image: api:0.2.0
    ports:
    - containerPort: 8000
---
apiVersion: v1
kind: Pod
metadata:
  name: api-pod-3
  labels:
    app: api
    version: 0.3.0
spec:
  containers:
  - name: api
    image: api:0.3.0
    ports:
    - containerPort: 8000
```

2. Appliquez le fichier et v√©rifiez que les 3 pods sont bien en cours d'ex√©cution :

```bash
kubectl apply -f k8s/pod.yaml
kubectl get pods
```

Vous devriez voir `api-pod-1`, `api-pod-2` et `api-pod-3` avec le statut `Running`.

3. Supprimez manuellement le deuxi√®me pod :

```bash
kubectl delete pod api-pod-2
kubectl get pods
```

`api-pod-2` a disparu et **ne r√©appara√Æt pas** ‚Äî un Pod d√©clar√© seul n'a aucun m√©canisme de self-healing.

4. Relancez `kubectl apply -f k8s/pod.yaml` :

```bash
kubectl apply -f k8s/pod.yaml
kubectl get pods
```

- Les pods d√©j√† existants (`api-pod-1` et `api-pod-3`) ne sont **pas recr√©√©s** ‚Äî `kubectl apply` d√©tecte qu'ils correspondent d√©j√† √† l'√©tat d√©clar√© et ne fait rien.
- Le pod supprim√© (`api-pod-2`) est **recr√©√©**, car il manque par rapport √† ce que d√©clare le fichier.

5. Nettoyez tout :

```bash
kubectl delete -f k8s/pod.yaml
```

---

#### üìã Namespaces

Par d√©faut, tous les pods que vous cr√©ez atterrissent dans le namespace `default` ‚Äî ils sont tous m√©lang√©s au m√™me endroit. Les Namespaces permettent de diviser logiquement les ressources d'un cluster en sous-groupes distincts, comme le montre le sch√©ma ci-dessous :
<p align="center">
    <img width="600" height="576" alt="image" src="https://github.com/user-attachments/assets/15bc9f09-e7c9-4c5d-8f6a-916b8146bf12" />
</p>

Chaque namespace est un espace isol√© : un pod nomm√© `api-pod` peut exister simultan√©ment dans `dev`, `qualif` et `prod` sans conflit. Ils servent typiquement √† isoler les environnements au sein du m√™me cluster.

1. Cr√©ez `k8s/namespace.yaml` :

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: dev
---
apiVersion: v1
kind: Namespace
metadata:
  name: qualif
---
apiVersion: v1
kind: Namespace
metadata:
  name: prod
```

Appliquez-le :

```bash
kubectl apply -f k8s/namespace.yaml
kubectl get namespaces
```

2. Cr√©ez `k8s/pods-namespaces.yaml` avec un pod par namespace :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: api-pod
  namespace: prod
  labels:
    app: api
    environment: prod
spec:
  containers:
  - name: api
    image: api:0.1.0
    ports:
    - containerPort: 8000
---
apiVersion: v1
kind: Pod
metadata:
  name: api-pod
  namespace: qualif
  labels:
    app: api
    environment: qualif
spec:
  containers:
  - name: api
    image: api:0.2.0
    ports:
    - containerPort: 8000
---
apiVersion: v1
kind: Pod
metadata:
  name: api-pod
  namespace: dev
  labels:
    app: api
    environment: dev
spec:
  containers:
  - name: api
    image: api:0.3.0
    ports:
    - containerPort: 8000
```

Appliquez-le :

```bash
kubectl apply -f k8s/pods-namespaces.yaml
```

3. V√©rifiez que chaque pod n'est visible que dans son namespace :

```bash
kubectl get pods -n prod
kubectl get pods -n qualif
kubectl get pods -n dev
```

Sans pr√©ciser de namespace, les pods ne sont pas visibles :

```bash
kubectl get pods   # Ne retourne rien ‚Äî le namespace par d√©faut est "default"
```

4. Filtrez tous les pods portant le label `environment=dev` dans tous les namespaces :

```bash
kubectl get pods -l environment=dev --all-namespaces
```

5. Nettoyez tout :

```bash
kubectl delete -f k8s/pods-namespaces.yaml
kubectl delete -f k8s/namespace.yaml
```

---

### d. Scaler avec un Deployment

Comme vu dans la section pr√©c√©dente, les Pods seuls ne se r√©parent pas, ne scalent pas, et sont difficiles √† mettre √† jour ou rollback.

Un **Deployment** est une ressource Kubernetes de plus haut niveau qui g√®re les Pods pour vous, en g√©rant automatiquement la r√©plication, le scaling et les mises √† jour tout en maintenant l'√©tat souhait√©.

Quand un Pod tombe ou est supprim√© dans un Deployment, Kubernetes en recr√©e automatiquement un nouveau pour converger vers l'√©tat d√©sir√©. Le Deployment garantit aussi des mises √† jour progressives en rempla√ßant graduellement les anciens Pods par les nouveaux, avec la possibilit√© de rollback en cas de probl√®me.

<p align="center">
    <img width="600" height="1725" alt="image" src="https://github.com/user-attachments/assets/7416921a-b258-42ae-9976-c215a8647959" />
</p>

#### üìã 10 r√©pliques avec auto-r√©paration

1. Cr√©ez un fichier `k8s/deployment.yaml` :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-deploy
spec:
  replicas: 10
  selector:
    matchLabels:
      app: api
  minReadySeconds: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1    # Au maximum 1 pod indisponible pendant la mise √† jour
      maxSurge: 1          # Au maximum 1 pod suppl√©mentaire cr√©√© pendant la mise √† jour
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
      - name: api-pod
        image: api:0.1.0
        ports:
        - containerPort: 8000
```

2. Appliquez le fichier et v√©rifiez que 10 pods sont bien en cours d'ex√©cution :

```bash
kubectl apply -f k8s/deployment.yaml
kubectl get pods
```

Vous devriez voir 10 pods avec des noms du type `api-deploy-xxxxxxxxx-xxxxx` et le statut `Running`.

3. Ouvrez un **second terminal** et lancez la commande suivante pour observer le cluster en temps r√©el :

```bash
kubectl get pods --watch
```

4. Dans votre **premier terminal**, supprimez un pod manuellement (remplacez `<nom-du-pod>` par l'un des noms list√©s √† l'√©tape 2) :

```bash
kubectl delete pod <nom-du-pod>
```

Observez le second terminal : Kubernetes d√©tecte imm√©diatement la disparition du pod et en recr√©e un nouveau pour maintenir le compte √† 10. C'est le **self-healing** en action.

5. Faites varier le nombre de r√©pliques en modifiant `replicas` dans le YAML, puis relancez `kubectl apply` :

```bash
kubectl apply -f k8s/deployment.yaml
kubectl get pods --watch
```

Kubernetes supprime ou cr√©e des pods progressivement jusqu'√† atteindre le nombre souhait√©.

> üí° **Deployment vs Pod**
>
> | | Pod seul | Deployment |
> |---|---|---|
> | Self-healing | ‚úó | ‚úì |
> | Scaling | ‚úó | ‚úì |
> | Rolling update | ‚úó | ‚úì |

---

### e. Exposer les pods avec un Service

Pour acc√©der √† l'application depuis un nom ou une adresse IP stable, on a besoin d'un **Service** Kubernetes plac√© devant un ensemble de pods.

Les pods ont des adresses IP √©ph√©m√®res qui changent √† chaque red√©marrage. Un Service fournit un point d'acc√®s stable (nom DNS + IP fixe) qui redirige le trafic vers les pods via leurs labels.

<p align="center">
    <img width="600" height="640" alt="image" src="https://github.com/user-attachments/assets/567cde9b-b16c-4122-bf61-362628abf8a1" />
</p>

#### üìã Cr√©ation d'un Service NodePort

1. V√©rifiez que votre Deployment est toujours actif :

```bash
kubectl get deploy api-deploy
```

2. Cr√©ez un fichier `k8s/service.yaml` :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: api-svc
  labels:
    app: api
spec:
  type: NodePort
  ports:
  - port: 8000          # Port expos√© √† l'int√©rieur du cluster
    nodePort: 30001     # Port accessible depuis votre machine
    protocol: TCP
  selector:
    app: api            # Redirige le trafic vers tous les pods avec le label app=api
```

3. Appliquez le Service :

```bash
kubectl apply -f k8s/service.yaml
kubectl get service api-svc
```

4. Ouvrez **http://localhost:30001/docs** dans votre navigateur. Le Service r√©partit automatiquement les requ√™tes entre les 10 pods.

5. Nettoyez tout :

```bash
kubectl delete -f k8s/service.yaml
kubectl delete -f k8s/deployment.yaml
```

> üí° La combinaison **Deployment ‚Üí R√©pliques de Pods ‚Üí Service** est le socle minimal pour survivre √† Kubernetes.

<p align="center">
    <img width="550" height="281" alt="image" src="https://github.com/user-attachments/assets/35ae0d75-6e72-498f-8c04-2f9d7bdf82c5" />
</p>

---

## 2. De Docker Compose vers Kubernetes

Dans le TD Docker Compose, vous avez d√©ploy√© un projet fullstack compos√© d'un frontend client et d'un backend de pr√©diction Iris. L'objectif ici est de porter cette m√™me architecture sur Kubernetes, en rempla√ßant `docker-compose.yml` par des manifestes YAML K8s.

| Docker Compose | Kubernetes |
|---|---|
| `service` | Deployment + Service |
| `scale: N` | `replicas: N` |
| `networks` | Labels + selectors |
| `volumes` | PersistentVolumeClaim |
| `environment` | ConfigMap / Secret |

#### üìã Exercice ‚Äî Application fullstack Iris sur Kubernetes

Vous allez reconstruire l'int√©gralit√© de l'architecture de pr√©diction Iris, cette fois sur K8s.

1. Reconstruisez l'image `mlops-client:latest` correspondant au frontend.

2. Entra√Ænez 3 mod√®les de pr√©diction Iris diff√©rents et empaquetez-les dans 3 images Docker distinctes : `mlops-server:0.1.0`, `mlops-server:0.2.0` et `mlops-server:0.3.0`. Chaque image doit exposer un endpoint `/version` indiquant sa version.

3. Cr√©ez un Deployment et un Service pour le frontend (`mlops-client:latest`).

4. Cr√©ez un Deployment avec 3 r√©pliques et un Service pour le backend (`mlops-server:0.1.0`).

5. Connectez le frontend au backend en utilisant le nom du Service comme URL dans le code Python. Par exemple, si votre service backend s'appelle `mlops-api-service`, l'URL √† utiliser sera `http://mlops-api-service:8000`. Kubernetes r√©sout ce nom DNS automatiquement.

6. V√©rifiez que le frontend est accessible depuis le navigateur et que les pr√©dictions fonctionnent.

> üìù **Pour la suite**
>
> Conservez ce d√©ploiement Iris actif : il servira de base pour la Fiche 2, qui portera sur les strat√©gies de mise √† jour (Rolling Update, Blue/Green, Canary).

---

## R√©capitulatif des commandes essentielles

| Commande | Description |
|---|---|
| `kubectl apply -f fichier.yaml` | Cr√©er ou mettre √† jour une ressource |
| `kubectl delete -f fichier.yaml` | Supprimer les ressources d√©clar√©es |
| `kubectl get pods` | Lister les pods du namespace courant |
| `kubectl get pods -l app=api` | Filtrer les pods par label |
| `kubectl describe pod <nom>` | D√©tails complets d'un pod |
| `kubectl logs <pod>` | Afficher les logs d'un pod |
| `kubectl exec -it <pod> -- /bin/bash` | Ouvrir un shell dans un pod |
| `kubectl port-forward <pod> 8000:8000` | Exposer un pod en local |
| `kubectl get deploy <nom> --watch` | Observer un deployment en temps r√©el |
| `kubectl rollout undo deployment/<nom>` | Annuler la derni√®re mise √† jour |
